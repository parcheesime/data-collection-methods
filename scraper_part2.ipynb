{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Part 2\n",
    "### Combine Pandas & Beautifulsoup to get data from a web site\n",
    "\n",
    "[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> assign url to variable, type Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = input('Enter URL: ')\n",
    "html_scraped = requests.get(url)\n",
    "type(html_scraped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create a parse tree from text based web file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_scraped.text, 'html.parser')\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n <head>\\n  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\\n  <meta name=\"ir-site-verification-token\" value=\"-1398349336\"/>\\n  <link href=\"https://storage.googleapis.com/lds-v2-static/static/css/bootstrap.min.css\" rel=\"stylesheet\"/>\\n  <link href=\"https://storage.googleapis.com/lds-v2-static/static/scss/main.min.css\" rel=\"stylesheet\"/>\\n  <script>\\n   window.page_redirects = \"\";\\n  </script>\\n  <link href=\"https://storage.googleapis.com/lds-v2-static/static/imgs/favicon.ico\" rel=\"shortcut icon\" type=\"image/png\"/>\\n  <script>\\n   (function (i, s, o, g, r, a, m) {\\n            i[\\'GoogleAnalyticsObject\\'] = r;\\n            i[r] = i[r] || function () {\\n                (i[r].q = i[r].q || []).push(arguments)\\n            }, i[r].l = 1 * new Date();\\n            a = s.createElement(o),\\n                m = s.getElementsByTagName(o)[0];\\n            a.async = 1;\\n            a.src = g;\\n            m.parentNode.insertBefore(a, m)\\n        })(window, document, \\'script\\', \\'https://www.google-analytics.com/analytics.js\\', \\'ga\\');\\n        ga(\\'create\\', \\'UA-66214322-1\\', \\'auto\\');\\n        ga(\\'require\\', \\'GTM-M2T2BZ4\\');\\n        ga(\\'send\\', \\'pageview\\');\\n  </script>\\n  <script>\\n   (function (w, d, s, l, i) {\\n        w[l] = w[l] || [];\\n        w[l].push({\\n            \\'gtm.start\\':\\n                new Date().getTime(), event: \\'gtm.js\\'\\n        });\\n        var f = d.getElementsByTagName(s)[0],\\n            j = d.createElement(s), dl = l != \\'dataLayer\\' ? \\'&l=\\' + l : \\'\\';\\n        j.async = true;\\n        j.src =\\n            \\'https://www.googletagmanager.com/gtm.js?id=\\' + i + dl;\\n        f.parentNode.insertBefore(j, f);\\n    })(window, document, \\'script\\', \\'dataLayer\\', \\'GTM-TKDFRWD\\');\\n  </script>\\n  <title>\\n   Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup â€“ LearnDataSci\\n  </title>\\n  <meta content=\"Request and wrangling HTML using two of the most popular Python libraries for web scraping: requests and BeautifulSoup.\" name=\"description\"/>\\n  <meta name=\"twitter:card\" value=\"summary\"/>\\n  <meta content=\"Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup\" property=\"og:title\"/>\\n  <meta content=\"article\" property=\"og:type\"/>\\n  <meta content=\"https://www.learndatasci.com/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/\" property=\"og:url\"/>\\n  <meta content=\"https://storage.googleapis.com/lds-media/images/Web_Scraping_with_Python_BeautifulSoup_and_Req.width-745.jpg\" property=\"og:image\"/>\\n </head>\\n <body class=\"template-blogpage template-blog-page\">\\n  <div class=\"wrapper\">\\n   <div class=\"navbar navbar-fixed-top active-bar\" role=\"navigation\">\\n    <div class=\"header-cta\">\\n     The internet\\'s best data science courses\\n     <a href=\"/best-data-science-online-courses/\">\\n      View Courses\\n     </a>\\n    </div>\\n    <div class=\"fluid-container\">\\n     <div class=\"navbar-header\">\\n      <button class=\"navbar-toggle\" data-target=\".navbar-collapse\" data-toggle=\"collapse\" type=\"button\">\\n       <span class=\"sr-only\">\\n        Toggle navigation\\n       </span>\\n       <span class=\"icon-bar\">\\n       </span>\\n       <span class=\"icon-bar\">\\n       </span>\\n       <span class=\"icon-bar\">\\n       </span>\\n      </button>\\n      <a class=\"navbar-brand\" data-placement=\"bottom\" href=\"/\" title=\"Learn Data Science - Tutorials, Books, Courses, and More\">\\n       <svg class=\"primary-logo\" height=\"65\" viewbox=\"0 0 239 65\" width=\"239\" xmlns=\"http://www.w3.org/2000/svg\">\\n        <defs>\\n         <style>\\n          .cls-1 { fill: #edbd17; } .cls-1, .cls-2, .cls-3 { fill-rule: evenodd; } .cls-2 { fill: #851836; } .cls-3 { fill: #cacaca; }\\n         </style>\\n        </defs>\\n        <path class=\"cls-1\" d=\"M63.606,64V48.5H47.954V64H63.606ZM32.3,64V2H1V64H32.3Z\" id=\"L\">\\n        </path>\\n        <path class=\"cls-2\" d=\"M135.019,63.988v-51H151.1v51H135.019Zm-48.257,0v-62h32.171v62H86.762Z\" id=\"D\">\\n        </path>\\n        <path class=\"cls-3\" d=\"M190.069,64V48.5H174.418V64h15.651Zm46.954,0V33h-31.3V64h31.3Zm-31.3-31V2h-31.3V33h31.3Zm31.3-15.5V2H221.372V17.5h15.651Z\" id=\"S\">\\n        </path>\\n       </svg>\\n      </a>\\n     </div>\\n     <div class=\"navbar-collapse collapse pull-right\">\\n      <ul class=\"nav navbar-nav\">\\n       <li class=\"\">\\n        <a href=\"/daily/\">\\n         Daily\\n        </a>\\n       </li>\\n       <li class=\"dropdown\">\\n        <a class=\"dropdown-toggle\" data-toggle=\"dropdown\" href=\"#\">\\n         Learning\\n         <b class=\"caret\">\\n          <svg height=\"100%\" id=\"arrow-down\" viewbox=\"0 0 32 32\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\">\\n           <path d=\"M31.296 7.68c-.256-.32-.704-.512-1.216-.512-.448 0-.896.192-1.216.512L16 20.736 3.2 7.68c-.256-.32-.704-.512-1.216-.512-.448 0-.896.192-1.216.448S.256 8.32.256 8.768c0 .512.192.96.512 1.28L14.72 24.32c.32.32.704.512 1.152.512.256 0 .512-.064.768-.192.128-.064.256-.128.384-.128l.128-.064 14.016-14.336c.768-.64.704-1.728.128-2.432z\">\\n           </path>\\n          </svg>\\n         </b>\\n        </a>\\n        <ul class=\"dropdown-menu\">\\n         <li>\\n          <a href=\"/data-science-curriculum/\">\\n           Curriculum\\n          </a>\\n         </li>\\n         <li>\\n          <a href=\"/tutorials/\">\\n           Tutorials\\n          </a>\\n         </li>\\n         <li>\\n          <a href=\"/articles/\">\\n           Articles\\n          </a>\\n         </li>\\n         <li>\\n          <a href=\"/glossary/\">\\n           Glossary\\n          </a>\\n         </li>\\n         <li>\\n          <a href=\"/books/\">\\n           Books\\n          </a>\\n         </li>\\n         <li>\\n          <a href=\"/solutions/\">\\n           Solutions\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n       <li class=\"dropdown\">\\n        <a class=\"dropdown-toggle\" data-toggle=\"dropdown\" href=\"#\">\\n         Courses\\n         <b class=\"caret\">\\n          <svg height=\"100%\" id=\"arrow-down\" viewbox=\"0 0 32 32\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\">\\n           <path d=\"M31.296 7.68c-.256-.32-.704-.512-1.216-.512-.448 0-.896.192-1.216.512L16 20.736 3.2 7.68c-.256-.32-.704-.512-1.216-.512-.448 0-.896.192-1.216.448S.256 8.32.256 8.768c0 .512.192.96.512 1.28L14.72 24.32c.32.32.704.512 1.152.512.256 0 .512-.064.768-.192.128-.064.256-.128.384-.128l.128-.064 14.016-14.336c.768-.64.704-1.728.128-2.432z\">\\n           </path>\\n          </svg>\\n         </b>\\n        </a>\\n        <ul class=\"dropdown-menu\">\\n         <li>\\n          <a href=\"/best-data-science-online-courses/\">\\n           Data Science\\n          </a>\\n         </li>\\n         <li>\\n          <a href=\"/best-data-analytics-courses/\">\\n           Data Analytics\\n          </a>\\n         </li>\\n         <li>\\n          <a href=\"/best-machine-learning-courses/\">\\n           Machine Learning\\n          </a>\\n         </li>\\n         <li>\\n          <a href=\"/best-python-courses/\">\\n           Python\\n          </a>\\n         </li>\\n         <li>\\n          <a href=\"/best-sql-courses/\">\\n           SQL\\n          </a>\\n         </li>\\n         <li>\\n          <a href=\"/best-excel-courses/\">\\n           Excel\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n       <li class=\"\">\\n        <a href=\"/team/\">\\n         Team\\n        </a>\\n       </li>\\n       <li class=\"social-menu-icons\">\\n        <a alt=\"GitHub\" href=\"https://github.com/LearnDataSci\">\\n         <img src=\"https://storage.googleapis.com/lds-media/documents/github-ico.svg\" width=\"30\"/>\\n         <span>\\n          466\\n         </span>\\n        </a>\\n       </li>\\n       <li class=\"social-menu-icons\">\\n        <a alt=\"Twitter\" href=\"http://twitter.com/learndatasci\">\\n         <img src=\"https://storage.googleapis.com/lds-media/documents/twitter_Gvy5lp8.svg\" width=\"30\"/>\\n         <span>\\n          2.7K\\n         </span>\\n        </a>\\n       </li>\\n      </ul>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"header-content fluid-container\">\\n   </div>\\n   <div class=\"container-fluid\" style=\"padding-top: 100px;\">\\n    <div class=\"blog-category-tag\">\\n     <span>\\n      You are reading\\n      <b>\\n       <a href=\"/tutorials\">\\n        tutorials\\n       </a>\\n      </b>\\n     </span>\\n    </div>\\n    <article class=\"article-content\">\\n     <div class=\"social-sidebar pull-left waypoint\">\\n      <div class=\"share sticky\">\\n       <div class=\"ttl-shares\">\\n        <span class=\"dynamic-share\">\\n         29\\n        </span>\\n        <span class=\"share-info\">\\n         SHARES\\n        </span>\\n       </div>\\n       <a class=\"st_linkedin_large icon-linkedin2\" displaytext=\"LinkedIn\" href=\"https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3A%2F%2Fwww.learndatasci.com%2Ftutorials%2Fultimate-guide-web-scraping-w-python-requests-and-beautifulsoup%2F&amp;summary=Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup\" st_title=\"Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup\" st_url=\"/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/\">\\n       </a>\\n       <a class=\"st_twitter_large icon-twitter\" displaytext=\"Tweet\" href=\"http://twitter.com/share?text=Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup&amp;url=https%3A%2F%2Fwww.learndatasci.com%2Ftutorials%2Fultimate-guide-web-scraping-w-python-requests-and-beautifulsoup%2F\" st_title=\"Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup\" st_url=\"/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/\">\\n       </a>\\n       <a class=\"st_facebook_large icon-facebook\" displaytext=\"Facebook\" href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.learndatasci.com%2Ftutorials%2Fultimate-guide-web-scraping-w-python-requests-and-beautifulsoup%2F\" st_title=\"Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup\" st_url=\"/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/\">\\n       </a>\\n       <a class=\"st_email_large icon-reddit\" displaytext=\"Email\" href=\"http://www.reddit.com/submit?url=https%3A%2F%2Fwww.learndatasci.com%2Ftutorials%2Fultimate-guide-web-scraping-w-python-requests-and-beautifulsoup%2F&amp;title=Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup\" st_title=\"Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup\" st_url=\"/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/\">\\n       </a>\\n       <a class=\"st_sharethis_large icon-hackernews\" displaytext=\"ShareThis\" href=\"https://news.ycombinator.com/submitlink?uhttps%3A%2F%2Fwww.learndatasci.com%2Ftutorials%2Fultimate-guide-web-scraping-w-python-requests-and-beautifulsoup%2F&amp;t=LearnDataSci\" st_title=\"Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup\" st_url=\"/tutorials/ultimate-guide-web-scraping-w-python-requests-and-beautifulsoup/\">\\n       </a>\\n      </div>\\n     </div>\\n     <div class=\"article-content-wrapper\">\\n      <div class=\"index-content clearfix\">\\n       <div class=\"main-container\">\\n        <div class=\"article-header-photo\">\\n         <img alt=\"Web Scraping with Python BeautifulSoup and Requests\" height=\"160\" src=\"https://storage.googleapis.com/lds-media/images/Web_Scraping_with_Python_Beautiful.2e16d0ba.fill-800x160.jpg\" width=\"800\"/>\\n        </div>\\n        <div class=\"meta-wrap\">\\n         <div class=\"meta author\">\\n          <img alt=\"Brendan Martin\" height=\"150\" src=\"https://storage.googleapis.com/lds-media/images/Brendan-Martin.width-150.jpg\" width=\"150\"/>\\n          <div class=\"r-side\">\\n           <span>\\n            <b>\\n             Author:\\n            </b>\\n            <a href=\"/author/brendan\">\\n             Brendan Martin\\n            </a>\\n           </span>\\n           <br/>\\n           <b>\\n            Founder of LearnDataSci\\n           </b>\\n          </div>\\n         </div>\\n         <div class=\"tags\" id=\"Tags\">\\n         </div>\\n        </div>\\n        <h1 style=\"color:#e2c03b;\">\\n         Ultimate Guide to Web Scraping with Python Part 1: Requests and BeautifulSoup\\n        </h1>\\n        <div class=\"intro\">\\n         <p>\\n          Part one of this series focuses on requesting and wrangling HTML using two of the most popular Python libraries for web scraping: requests and BeautifulSoup\\n         </p>\\n        </div>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            After the 2016 election I became much more interested in media bias and the manipulation of individuals through advertising. This series will be a walkthrough of a web scraping project that monitors political news from both left and right wing media outlets and performs an analysis on the rhetoric being used, the ads being displayed, and the sentiment of certain topics.\\n           </p>\\n           <p>\\n           </p>\\n           <p>\\n            <a href=\"https://github.com/LearnDataSci/article-resources/tree/master/Ultimate%20Guide%20to%20Web%20Scraping/Part%201%20-%20Requests%20and%20BeautifulSoup\">\\n             <b>\\n              Notebook for this tutorial\\n             </b>\\n             â€” GitHub\\n            </a>\\n           </p>\\n           <p>\\n           </p>\\n           <p>\\n            The first part of the series will we be getting media bias data and focus on only working locally on your computer, but if you wish to learn how to deploy something like this into production, feel free to leave a comment and let me know.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"help-blocks row prereq-style\">\\n          <div class=\"col-md-2 text-center\">\\n           <div class=\"bulb-wrap\">\\n            <img src=\"https://storage.googleapis.com/lds-v2-static/static/imgs/icons/lightbulb-brain.svg\" style=\"width:40px; max-width:100%;\"/>\\n           </div>\\n          </div>\\n          <div class=\"col-md-10\">\\n           <h3>\\n            You should already know:\\n           </h3>\\n           <div class=\"rich-text\">\\n            <ul>\\n             <li>\\n              Python fundamentals - lists, dicts, functions, loops -\\n              <a href=\"/out/coursera-programming-everybody-getting-started-python/\">\\n               learn on Coursera\\n              </a>\\n             </li>\\n             <li>\\n              Basic HTML\\n             </li>\\n            </ul>\\n           </div>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"help-blocks row\">\\n          <div class=\"col-md-2 text-center\">\\n           <div class=\"bulb-wrap\">\\n            <img src=\"https://storage.googleapis.com/lds-v2-static/static/imgs/icons/lightbulb-check.svg\" style=\"width:50px; max-width:100%;\"/>\\n           </div>\\n          </div>\\n          <div class=\"col-md-10\">\\n           <h3>\\n            You will learn:\\n           </h3>\\n           <div class=\"rich-text\">\\n            <ul>\\n             <li>\\n              Requesting web pages\\n             </li>\\n             <li>\\n              Parsing HTML\\n             </li>\\n             <li>\\n              Saving and loading scraped data\\n             </li>\\n             <li>\\n              Scraping multiple pages in a row\\n             </li>\\n            </ul>\\n           </div>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h2 id=\"Limityourimpactwhenscraping\">\\n           Limit your impact when scraping\\n          </h2>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Every time you load a web page you\\'re making a request to a server, and when you\\'re just a human with a browser there\\'s not a lot of damage you can do. With a Python script that can execute thousands of requests a second if coded incorrectly, you could end up costing the website owner a lot of money and possibly bring down their site (see\\n            <a href=\"https://en.wikipedia.org/wiki/Denial-of-service_attack\">\\n             Denial-of-service attack (DoS)\\n            </a>\\n            ).\\n           </p>\\n           <p>\\n            With this in mind, we want to be very careful with how we program scrapers to avoid crashing sites and causing damage. Every time we scrape a website we want to attempt to\\n            <b>\\n             make only one request per page\\n            </b>\\n            . We don\\'t want to be making a request every time our parsing or other logic doesn\\'t work out, so we need to parse only after we\\'ve saved the page locally.\\n           </p>\\n           <p>\\n            If I\\'m just doing some quick tests, I\\'ll usually start out in a Jupyter notebook because you can request a web page in one cell and have that web page available to every cell below it without making a new request. Since this article is available as a Jupyter notebook, you will see how it works if you choose that format.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h3 id=\"HowtosaveHTMLlocally\">\\n           How to save HTML locally\\n          </h3>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            After we make a request and retrieve a web page\\'s content, we can store that content locally with Python\\'s\\n            <code>\\n             open()\\n            </code>\\n            function. To do so we need to use the argument\\n            <code>\\n             wb\\n            </code>\\n            , which stands for \"write bytes\". This let\\'s us avoid any encoding issues when saving.\\n           </p>\\n           <p>\\n            Below is a function that wraps the\\n            <code>\\n             open()\\n            </code>\\n            function to reduce a lot of repetitive coding later on:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">def save_html(html, path):\\n    with open(path, \\'wb\\') as f:\\n        f.write(html)\\n        \\n        \\nsave_html(r.content, \\'google_com\\')</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Assume we have captured the HTML from google.com in\\n            <code>\\n             html\\n            </code>\\n            , which you\\'ll see later how to do. After running this function we will now have a file in the same directory as this notebook called\\n            <code>\\n             google_com\\n            </code>\\n            that contains the HTML.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h3 id=\"HowtoopenreadHTMLfromalocalfile\">\\n           How to open/read HTML from a local file\\n          </h3>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            To retrieve our saved file we\\'ll make another function to wrap reading the HTML back into\\n            <code>\\n             html\\n            </code>\\n            . We need to use\\n            <code>\\n             rb\\n            </code>\\n            for \"read bytes\" in this case.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">def open_html(path):\\n    with open(path, \\'rb\\') as f:\\n        return f.read()\\n    \\n    \\nhtml = open_html(\\'google_com\\')</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            The open function is doing just the opposite: read the HTML from\\n            <code>\\n             google_com\\n            </code>\\n            . If our script fails, notebook closes, computer shuts down, etc., we no longer need to request Google again, lessening our impact on their servers. While it doesn\\'t matter much with Google since they have a lot of resources, smaller sites with smaller servers will benefit from this.\\n           </p>\\n           <p>\\n            I save almost every page and parse later when web scraping as a safety precaution.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h3 id=\"Followtherulesforscrapersandbots\">\\n           Follow the rules for scrapers and bots\\n          </h3>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            Each site usually has a\\n            <b>\\n             robots.txt\\n            </b>\\n            on the root of their domain. This is where the website owner explicitly states what bots are allowed to do on their site. Simply go to example.com/robots.txt and you should find a text file that looks something like this:\\n           </p>\\n           <p>\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/text\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-text\">User-agent: * \\nCrawl-delay: 10 \\nAllow: /pages/ \\nDisallow: /scripts/  \\n\\n# more stuff</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            The\\n            <i>\\n             User-agent\\n            </i>\\n            field is the name of the bot and the rules that follow are what the bot should follow. Some robots.txt will have many User-agents with different rules. Common bots are\\n            <i>\\n             googlebot\\n            </i>\\n            ,\\n            <i>\\n             bingbot\\n            </i>\\n            , and\\n            <i>\\n             applebot\\n            </i>\\n            , all of which you can probably guess the purpose and origin of.\\n           </p>\\n           <p>\\n            We don\\'t really need to provide a User-agent when scraping, so User-agent: * is what we would follow. A * means that the following rules apply to\\n            <i>\\n             all\\n            </i>\\n            bots (that\\'s us).\\n           </p>\\n           <p>\\n            The\\n            <i>\\n             Crawl-delay\\n            </i>\\n            tells us the number of seconds to wait before requests, so in this example we need to wait 10 seconds before making another request.\\n           </p>\\n           <p>\\n            <i>\\n             Allow\\n            </i>\\n            gives us specific URLs we\\'re\\n            <i>\\n             allowed\\n            </i>\\n            to request with bots, and vice versa for\\n            <i>\\n             Disallow\\n            </i>\\n            . In this example we\\'re allowed to request anything in the\\n            <b>\\n             /pages/\\n            </b>\\n            subfolder which means anything that starts with\\n            <b>\\n             example.com/pages/\\n            </b>\\n            . On the other hand, we are disallowed from scraping anything from the\\n            <b>\\n             /scripts/\\n            </b>\\n            subfolder.\\n           </p>\\n           <p>\\n            Many times you\\'ll see a * next to Allow or Disallow which means you are either allowed or not allowed to scrape everything on the site.\\n           </p>\\n           <p>\\n            Sometimes there will be a disallow all pages followed by allowed pages like this:\\n           </p>\\n           <p>\\n           </p>\\n           <p>\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/text\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-text\">Disallow: * \\nAllow: /pages/</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            This means that you\\'re not allowed to scrape anything\\n            <i>\\n             except\\n            </i>\\n            the subfolder\\n            <i>\\n             /pages/\\n            </i>\\n            . Essentially, you just want to read the rules in order where the next rule overrides the previous rule.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h2 id=\"ScrapingProjectGettingMediaBiasData\">\\n           Scraping Project: Getting Media Bias Data\\n          </h2>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            This project will primarily be run through a Jupyter notebook, which is done for teaching purposes and is not the usual way scrapers are programmed. After showing you the pieces, we\\'ll put it all together into a Python script that can be run from command line or your IDE of choice.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h3 id=\"Makingwebrequests\">\\n           Making web requests\\n          </h3>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            With Python\\'s\\n            <code>\\n             requests\\n            </code>\\n            (\\n            <code>\\n             pip install requests\\n            </code>\\n            ) library we\\'re getting a web page by using\\n            <code>\\n             get()\\n            </code>\\n            on the URL. The response\\n            <code>\\n             r\\n            </code>\\n            contains many things, but using\\n            <code>\\n             r.content\\n            </code>\\n            will give us the HTML. Once we have the HTML we can then parse it for the data we\\'re interested in analyzing.\\n           </p>\\n           <p>\\n            There\\'s an interesting website called\\n            <i>\\n             AllSides\\n            </i>\\n            that has a\\n            <a href=\"https://www.allsides.com/media-bias/media-bias-ratings\">\\n             media bias rating table\\n            </a>\\n            where users can agree or disagree with the rating.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"caption-image\">\\n          <div class=\"caption-img-wrap\">\\n           <figure class=\"captioned-images fullwidth-wrap\">\\n            <div class=\"attributed-wrap\" style=\"\">\\n             <img class=\"img-responsive\" height=\"591\" loading=\"lazy\" src=\"https://storage.googleapis.com/lds-media/images/Media_Bias_Ratings_AllSides.width-1200.jpg\" width=\"1200\"/>\\n            </div>\\n            <figcaption>\\n             Media Bias Ratings on AllSides\\n            </figcaption>\\n           </figure>\\n          </div>\\n          <a class=\"zoom-in-img\" href=\"https://storage.googleapis.com/lds-media/images/Media_Bias_Ratings_AllSides.width-1200.jpg\" target=\"_blank\">\\n           <svg enable-background=\"new 0 0 24 24\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\">\\n            <rect fill=\"none\" height=\"24\" width=\"24\">\\n            </rect>\\n            <polygon points=\"21,11 21,3 13,3 16.29,6.29 6.29,16.29 3,13 3,21 11,21 7.71,17.71 17.71,7.71\">\\n            </polygon>\\n           </svg>\\n          </a>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Since there\\'s nothing in their robots.txt that disallows us from scraping this section of the site, I\\'m assuming it\\'s okay to go ahead and extract this data for our project. Let\\'s request the this first page:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">import requests\\n\\nurl = \\'https://www.allsides.com/media-bias/media-bias-ratings\\'\\n\\nr = requests.get(url)\\n\\nprint(r.content[:100])</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed out-code\">\\n          <div class=\"out\">\\n           Out:\\n          </div>\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">b\\'&lt;!DOCTYPE html&gt;\\\\n&lt;!--[if IEMobile 7]&gt;&lt;html class=\"iem7\"  lang=\"en\" dir=\"ltr\"&gt;&lt;![endif]--&gt;\\\\n&lt;!--[if lte\\'</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Since we essentially have a giant string of HTML, we can print a slice of 100 characters to confirm we have the source of the page. Let\\'s start extracting data.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h3 id=\"ParsingHTMLwithBeautifulSoup\">\\n           Parsing HTML with BeautifulSoup\\n          </h3>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h4 id=\"WhatdoesBeautifulSoupdo\">\\n           What does BeautifulSoup do?\\n          </h4>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            We used\\n            <code>\\n             requests\\n            </code>\\n            to get the page from the AllSides server, but now we need the BeautifulSoup library (\\n            <code>\\n             pip install beautifulsoup4\\n            </code>\\n            ) to parse HTML and XML. When we pass our HTML to the BeautifulSoup constructor we get an object in return that we can then navigate like the original tree structure of the DOM.\\n           </p>\\n           <p>\\n            This way we can find elements using names of tags, classes, IDs, and through relationships to other elements, like getting the children and siblings of elements.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h4 id=\"Creatinganewsoupobject\">\\n           Creating a new soup object\\n          </h4>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            We create a new BeautifulSoup object by passing the constructor our newly acquired HTML content and the type of parser we want to use:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">from bs4 import BeautifulSoup\\n\\nsoup = BeautifulSoup(r.content, \\'html.parser\\')</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            This\\n            <code>\\n             soup\\n            </code>\\n            object defines a bunch of methods â€” many of which can achieve the same result â€” that we can use to extract data from the HTML. Let\\'s start with finding elements.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h4 id=\"Findingelementsanddata\">\\n           Finding elements and data\\n          </h4>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            To find elements and data inside our HTML we\\'ll be using\\n            <code>\\n             select_one\\n            </code>\\n            , which returns a single element, and\\n            <code>\\n             select\\n            </code>\\n            , which returns a list of elements (even if only one item exists). Both of these methods use CSS selectors to find elements, so if you\\'re rusty on how CSS selectors work here\\'s a quick refresher:\\n           </p>\\n           <p>\\n            <b>\\n             A CSS selector refresher\\n            </b>\\n           </p>\\n           <ol>\\n            <li>\\n             To get a tag, such as\\n             <code>\\n              &lt;a&gt;&lt;/a&gt;\\n             </code>\\n             ,\\n             <code>\\n              &lt;body&gt;&lt;/body&gt;\\n             </code>\\n             , use the naked name for the tag. E.g.\\n             <code>\\n              select_one(\\'a\\')\\n             </code>\\n             gets an anchor/link element,\\n             <code>\\n              select_one(\\'body\\')\\n             </code>\\n             gets the body element\\n             <br/>\\n             <br/>\\n            </li>\\n            <li>\\n             <code>\\n              .temp\\n             </code>\\n             gets an element with a class of\\n             <b>\\n              temp\\n             </b>\\n             , E.g. to get\\n             <code>\\n              &lt;a class=\"temp\"&gt;&lt;/a&gt;\\n             </code>\\n             use\\n             <code>\\n              select_one(\\'.temp\\')\\n             </code>\\n             <br/>\\n             <br/>\\n            </li>\\n            <li>\\n             <code>\\n              #temp\\n             </code>\\n             gets an element with an id of\\n             <b>\\n              temp\\n             </b>\\n             , E.g. to get\\n             <code>\\n              &lt;a id=\"temp\"&gt;&lt;/a&gt;\\n             </code>\\n             use\\n             <code>\\n              select_one(\\'#temp\\')\\n             </code>\\n             <br/>\\n             <br/>\\n            </li>\\n            <li>\\n             <code>\\n              .temp.example\\n             </code>\\n             gets an element with both classes\\n             <b>\\n              temp\\n             </b>\\n             and\\n             <b>\\n              example\\n             </b>\\n             , E.g. to get\\n             <code>\\n              &lt;a class=\"temp example\"&gt;&lt;/a&gt;\\n             </code>\\n             use\\n             <code>\\n              select_one(\\'.temp.example\\')\\n             </code>\\n             <br/>\\n             <br/>\\n            </li>\\n            <li>\\n             <code>\\n              .temp a\\n             </code>\\n             gets an anchor element nested inside of a parent element with class\\n             <b>\\n              temp\\n             </b>\\n             , E.g. to get\\n             <code>\\n              &lt;div class=\"temp\"&gt;&lt;a&gt;&lt;/a&gt;&lt;/div&gt;\\n             </code>\\n             use\\n             <code>\\n              select_one(\\'.temp a\\')\\n             </code>\\n             . Note the space between\\n             <code>\\n              .temp\\n             </code>\\n             and\\n             <code>\\n              a\\n             </code>\\n             .\\n             <br/>\\n             <br/>\\n            </li>\\n            <li>\\n             <code>\\n              .temp .example\\n             </code>\\n             gets an element with class\\n             <b>\\n              example\\n             </b>\\n             nested inside of a parent element with class\\n             <b>\\n              temp\\n             </b>\\n             , E.g. to get\\n             <code>\\n              &lt;div class=\"temp\"&gt;&lt;a class=\"example\"&gt;&lt;/a&gt;&lt;/div&gt;\\n             </code>\\n             use\\n             <code>\\n              select_one(\\'.temp .example\\')\\n             </code>\\n             . Again, note the space between\\n             <code>\\n              .temp\\n             </code>\\n             and\\n             <code>\\n              .example\\n             </code>\\n             . The space tells the selector that the class after the space is a child of the class before the space.\\n             <br/>\\n             <br/>\\n            </li>\\n            <li>\\n             ids, such as\\n             <code>\\n              &lt;a id=one&gt;&lt;/a&gt;\\n             </code>\\n             , are unique so you can usually use the id selector by itself to get the right element. No need to do nested selectors when using ids.\\n            </li>\\n           </ol>\\n           <p>\\n           </p>\\n           <p>\\n            There\\'s many more selectors for for doing various tasks, like selecting certain child elements, specific links, etc., that you can\\n            <a href=\"https://www.w3schools.com/cssref/css_selectors.asp\">\\n             look up when needed\\n            </a>\\n            . The selectors above get us pretty close to everything we would need for now.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            <b>\\n             Tips on figuring out how to select certain elements\\n            </b>\\n           </p>\\n           <p>\\n            Most browsers have a quick way of finding the selector for an element using their developer tools. In Chrome, we can quickly find selectors for elements by\\n           </p>\\n           <ol>\\n            <li>\\n             Right-click on the the element then select \"Inspect\" in the menu. Developer tools opens and and highlights the element we right-clicked\\n             <br/>\\n            </li>\\n            <li>\\n             Right-click the code element in developer tools, hover over \"Copy\" in the menu, then click \"Copy selector\"\\n            </li>\\n           </ol>\\n           <p>\\n            Sometimes it\\'ll be a little off and we need to scan up a few elements to find the right one. Here\\'s what it looks like to find the selector and Xpath, another type of selector, in Chrome:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <video controls=\"\" src=\"https://storage.googleapis.com/lds-media/documents/css_selector_vs_xpath.mp4\" width=\"700px\">\\n         </video>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h3 id=\"LetsstartGettingdataoutofatable\">\\n           Let\\'s start! Getting data out of a table\\n          </h3>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Our data is housed in a table on AllSides, and by inspecting the header element we can find the code that renders the table and rows. What we need to do is\\n            <code>\\n             select\\n            </code>\\n            all the rows from the table and then parse out the information from each row.\\n           </p>\\n           <p>\\n           </p>\\n           <p>\\n            Here\\'s how to quickly find the table in the source code:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <video controls=\"\" src=\"https://storage.googleapis.com/lds-media/documents/finding_table_in_HTML.mp4\" width=\"700px\">\\n         </video>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            Simplifying the table\\'s HTML, the structure looks like this (comments\\n            <code>\\n             &lt;!-- --&gt;\\n            </code>\\n            added by me):\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/javascript\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-javascript\">&lt;table&gt;\\n    &lt;thead&gt; \\n        &lt;!-- header information --&gt; \\n    &lt;/thead&gt;\\n    &lt;tbody&gt;\\n        &lt;tr class=\"odd views-row-first\"&gt;                                       &lt;!-- begin table row --&gt;\\n            &lt;td class=\"views-field views-field-title source-title\"&gt;            &lt;!-- table cell --&gt;\\n                &lt;!-- outlet name --&gt;\\n            &lt;/td&gt; \\n            &lt;td class=\"views-field views-field-field-bias-image\"&gt;              &lt;!-- table cell --&gt;\\n                &lt;!-- bias data --&gt;\\n            &lt;/td&gt; \\n            &lt;td class=\"views-field views-field-nothing-1 what-do-you-think\"&gt;   &lt;!-- table cell --&gt;\\n                &lt;!-- agree / disagree buttons --&gt;\\n            &lt;/td&gt; \\n            &lt;td class=\"views-field views-field-nothing community-feedback\"&gt;    &lt;!-- table cell --&gt;\\n                &lt;!-- agree / disagree data --&gt;\\n            &lt;/td&gt; \\n        &lt;/tr&gt;                                                                  &lt;!-- end table row --&gt;\\n        &lt;!-- more rows --&gt;\\n    &lt;/tbody&gt;\\n&lt;/table&gt;</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            So to get each row, we just select all\\n            <code>\\n             &lt;tr&gt;\\n            </code>\\n            inside\\n            <code>\\n             &lt;tbody&gt;\\n            </code>\\n            :\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">rows = soup.select(\\'tbody tr\\')</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            <code>\\n             tbody tr\\n            </code>\\n            tells the selector to extract all\\n            <code>\\n             &lt;tr&gt;\\n            </code>\\n            (\\n            <b>\\n             t\\n            </b>\\n            able\\n            <b>\\n             r\\n            </b>\\n            ow) tags that are children of the\\n            <code>\\n             &lt;tbody&gt;\\n            </code>\\n            body tag. If there were more than one table on this page we would have to make a more specific selector, but since this is the only table, we\\'re good to go.\\n           </p>\\n           <p>\\n            Now we have a list of HTML table rows that each contain four cells:\\n           </p>\\n           <ul>\\n            <li>\\n             News source name and link\\n            </li>\\n            <li>\\n             Bias data\\n            </li>\\n            <li>\\n             Agreement buttons\\n            </li>\\n            <li>\\n             Community feedback data\\n            </li>\\n           </ul>\\n           <p>\\n            Below is a breakdown of how to extract each one.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h4 id=\"Newssourcename\">\\n           News source name\\n          </h4>\\n         </div>\\n        </section>\\n        <section>\\n         <video controls=\"\" src=\"https://storage.googleapis.com/lds-media/documents/news_source_name.mp4\" width=\"700px\">\\n         </video>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Let\\'s look at the first cell:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/javascript\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-javascript\">&lt;td class=\"views-field views-field-title source-title\"&gt;\\n    &lt;a href=\"/news-source/abc-news-media-bias\"&gt;ABC News&lt;/a&gt;\\n&lt;/td&gt;</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            The outlet name (\\n            <i>\\n             ABC News\\n            </i>\\n            ) is the text of an anchor tag that\\'s nested inside a\\n            <code>\\n             &lt;td&gt;\\n            </code>\\n            tag, which is a cell â€” or\\n            <b>\\n             t\\n            </b>\\n            able\\n            <b>\\n             d\\n            </b>\\n            ata tag.\\n           </p>\\n           <p>\\n            Getting the outlet name is pretty easy: just get the first row in\\n            <code>\\n             rows\\n            </code>\\n            and run a\\n            <code>\\n             select_one\\n            </code>\\n            off that object:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">row = rows[0]\\n\\nname = row.select_one(\\'.source-title\\').text.strip()\\n\\nprint(name)</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed out-code\">\\n          <div class=\"out\">\\n           Out:\\n          </div>\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">ABC News</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            The only class we needed to use in this case was\\n            <code>\\n             .source-title\\n            </code>\\n            since\\n            <code>\\n             .views-field\\n            </code>\\n            looks to be just a class each row is given for styling and doesn\\'t provide any uniqueness.\\n           </p>\\n           <p>\\n            Notice that we didn\\'t need to worry about selecting the anchor tag\\n            <code>\\n             a\\n            </code>\\n            that contains the text. When we use\\n            <code>\\n             .text\\n            </code>\\n            is gets all text in that element, and since \"ABC News\" is the only text, that\\'s all we need to do. Bear in mind that using\\n            <code>\\n             select\\n            </code>\\n            or\\n            <code>\\n             select_one\\n            </code>\\n            will give you the whole element with the tags included, so we need\\n            <code>\\n             .text\\n            </code>\\n            to give us the text between the tags.\\n           </p>\\n           <p>\\n            <code>\\n             .strip()\\n            </code>\\n            ensures all the whitespace surrounding the name is removed. Many websites use whitespace as a way to visually pad the text inside elements so using\\n            <code>\\n             strip()\\n            </code>\\n            is always a good idea.\\n           </p>\\n           <p>\\n            You\\'ll notice that we can run BeautifulSoup methods right off one of the rows. That\\'s because the rows become their own BeautifulSoup objects when we make a select from another BeautifulSoup object. On the other hand, our\\n            <code>\\n             name\\n            </code>\\n            variable is no longer a BeautifulSoup object because we called\\n            <code>\\n             .text\\n            </code>\\n            .\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h4 id=\"Newssourcepagelink\">\\n           News source page link\\n          </h4>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            We also need the link to this news source\\'s page on AllSides. If we look back at the HTML we\\'ll see that in this case we\\n            <i>\\n             do\\n            </i>\\n            want to select the anchor in order to get the\\n            <code>\\n             href\\n            </code>\\n            that contains the link, so let\\'s do that:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">allsides_page = row.select_one(\\'.source-title a\\')[\\'href\\']\\nallsides_page = \\'https://www.allsides.com\\' + allsides_page\\n\\nprint(allsides_page)</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed out-code\">\\n          <div class=\"out\">\\n           Out:\\n          </div>\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">https://www.allsides.com/news-source/abc-news-media-bias</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            It is a relative path in the HTML, so we prepend the site\\'s URL to make it a link we can request later.\\n           </p>\\n           <p>\\n            Getting the link was a bit different than just selecting an element. We had to access an\\n            <i>\\n             attribute\\n            </i>\\n            (\\n            <code>\\n             href\\n            </code>\\n            ) of the element, which is done using brackets, like how we would access a Python dictionary. This will be the same for other attributes of elements, like\\n            <code>\\n             src\\n            </code>\\n            in images and videos.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h4 id=\"Biasrating\">\\n           Bias rating\\n          </h4>\\n         </div>\\n        </section>\\n        <section>\\n         <video controls=\"\" src=\"https://storage.googleapis.com/lds-media/documents/bias_rating.mp4\" width=\"700px\">\\n         </video>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            We can see that the rating is displayed as an image so how can we get the rating in words? Looking at the HTML notice the link that surrounds the image has the text we need:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/javascript\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-javascript\">&lt;td class=\"views-field views-field-field-bias-image\"&gt;\\n    &lt;a href=\"/media-bias/left-center\"&gt;\\n        &lt;img src=\"...\" width=\"144\" height=\"24\" alt=\"Political News Media Bias Rating: Lean Left\" title=\"Political News Media Bias Rating: Lean Left\"&gt;\\n    &lt;/a&gt;          \\n&lt;/td&gt;</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            We could also pull the\\n            <code>\\n             alt\\n            </code>\\n            attribute, but the link looks easier. Let\\'s grab it:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">bias = row.select_one(\\'.views-field-field-bias-image a\\')[\\'href\\']\\nbias = bias.split(\\'/\\')[-1]\\n\\nprint(bias)</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">left-center</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Here we selected the anchor tag by using the class name and tag together:\\n            <code>\\n             .views-field-field-bias-image\\n            </code>\\n            is the class of the\\n            <code>\\n             &lt;td&gt;\\n            </code>\\n            and\\n            <code>\\n             &lt;a&gt;\\n            </code>\\n            is for the anchor nested inside.\\n           </p>\\n           <p>\\n            After that we extract the\\n            <code>\\n             href\\n            </code>\\n            just like before, but now we only want the last part of the URL for the name of the bias so we split on slashes and get the last element of that split (\\n            <i>\\n             left-center\\n            </i>\\n            ).\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h4 id=\"Communityfeedbackdata\">\\n           Community feedback data\\n          </h4>\\n         </div>\\n        </section>\\n        <section>\\n         <video controls=\"\" src=\"https://storage.googleapis.com/lds-media/documents/agree_ratio_community_feedback.mp4\" width=\"700px\">\\n         </video>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            The last thing to scrape is the agree/disagree ratio from the community feedback area. The HTML of this cell is pretty convoluted due to the styling, but here\\'s the basic structure:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/javascript\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-javascript\">&lt;td class=\"views-field views-field-nothing community-feedback\"&gt;\\n    &lt;div class=\"getratingval\"&gt;\\n        &lt;div class=\"rate-widget-4 rate-widget clear-block rate-average rate-widget-yesno\" id=\"rate-node-76-4-1\"&gt;\\n             &lt;div class=\"item-list\"&gt;\\n                &lt;ul&gt;\\n                    &lt;li class=\"first\"&gt;\\n                        &lt;a class=\"rate-button rate-btn\" href=\"...\" id=\"rate-button-3\"&gt;agree&lt;/a&gt;\\n                    &lt;/li&gt;\\n                    &lt;li class=\"last\"&gt;\\n                        &lt;a class=\"rate-button rate-btn\" href=\"...\" id=\"rate-button-4\"&gt;disagree&lt;/a&gt;\\n                    &lt;/li&gt;\\n                &lt;/ul&gt;\\n            &lt;/div&gt;\\n            &lt;div class=\"rate-details\"&gt;\\n                &lt;span class=\"agree\"&gt;8241&lt;/span&gt;/&lt;span class=\"disagree\"&gt;6568&lt;/span&gt;\\n            &lt;/div&gt;\\n        &lt;/div&gt;\\n    &lt;/div&gt;\\n&lt;/td&gt;</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            The numbers we want are located in two\\n            <code>\\n             span\\n            </code>\\n            elements in the last\\n            <code>\\n             div\\n            </code>\\n            . Both\\n            <code>\\n             span\\n            </code>\\n            elements have classes that are unique in this cell so we can use them to make the selection:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">agree = row.select_one(\\'.agree\\').text\\nagree = int(agree)\\n\\ndisagree = row.select_one(\\'.disagree\\').text\\ndisagree = int(disagree)\\n\\nagree_ratio = agree / disagree\\n\\nprint(f\"Agree: {agree}, Disagree: {disagree}, Ratio {agree_ratio:.2f}\")</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed out-code\">\\n          <div class=\"out\">\\n           Out:\\n          </div>\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">Agree: 8411, Disagree: 6662, Ratio 1.26</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            Using\\n            <code>\\n             .text\\n            </code>\\n            will return a string, so we need to convert them to integers in order to calculate the ratio.\\n           </p>\\n           <p>\\n            <b>\\n             Side note:\\n            </b>\\n            If you\\'ve never seen this way of formatting print statements in Python, the\\n            <code>\\n             f\\n            </code>\\n            at the front allows us to insert variables right into the string using curly braces. The\\n            <code>\\n             :.2f\\n            </code>\\n            is a way to format floats to only show two decimals places.\\n           </p>\\n           <p>\\n            If you look at the page in your browser you\\'ll notice that they say how much the community is in agreement by using \"somewhat agree\", \"strongly agree\", etc. so how do we get that? If we try to select it:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">print(row.select_one(\\'.community-feedback-rating-page\\'))</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed out-code\">\\n          <div class=\"out\">\\n           Out:\\n          </div>\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">None</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            It shows up as None because this element is rendered with Javascript and\\n            <code>\\n             requests\\n            </code>\\n            can\\'t pull HTML rendered with Javascript. We\\'ll be looking at how to get data rendered with JS in a later article, but since this is the only piece of information that\\'s rendered this way we can manually recreate the text.\\n           </p>\\n           <p>\\n            To find the JS files they\\'re using, just CTRL+F for \".js\" in the page source and open the files in a new tab to look for that logic.\\n           </p>\\n           <p>\\n            It turned out the logic was located in the eleventh JS file and they have a function that calculates the text and color with these parameters:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"\">\\n          <div class=\"table-block table-style-default\">\\n           <div class=\"tbl-wrap fullwidth-wrap\">\\n            <div class=\"scrollable\">\\n             <table width=\"361px\">\\n              <thead>\\n               <tr>\\n                <td>\\n                 Range\\n                </td>\\n                <td>\\n                 Agreeance\\n                </td>\\n               </tr>\\n              </thead>\\n              <tbody>\\n               <tr>\\n                <td>\\n                 $ratio &gt; 3$\\n                </td>\\n                <td>\\n                 absolutely agrees\\n                </td>\\n               </tr>\\n               <tr>\\n                <td>\\n                 $2 &lt; ratio \\\\leq 3$\\n                </td>\\n                <td>\\n                 strongly agrees\\n                </td>\\n               </tr>\\n               <tr>\\n                <td>\\n                 $1.5 &lt; ratio \\\\leq 2$\\n                </td>\\n                <td>\\n                 agrees\\n                </td>\\n               </tr>\\n               <tr>\\n                <td>\\n                 $1 &lt; ratio \\\\leq 1.5$\\n                </td>\\n                <td>\\n                 somewhat agrees\\n                </td>\\n               </tr>\\n               <tr>\\n                <td>\\n                 $ratio = 1$\\n                </td>\\n                <td>\\n                 neutral\\n                </td>\\n               </tr>\\n               <tr>\\n                <td>\\n                 $0.67 &lt; ratio &lt; 1$\\n                </td>\\n                <td>\\n                 somewhat disgrees\\n                </td>\\n               </tr>\\n               <tr>\\n                <td>\\n                 $0.5 &lt; ratio \\\\leq 0.67$\\n                </td>\\n                <td>\\n                 disgrees\\n                </td>\\n               </tr>\\n               <tr>\\n                <td>\\n                 $0.33 &lt; ratio \\\\leq 0.5$\\n                </td>\\n                <td>\\n                 strongly disagrees\\n                </td>\\n               </tr>\\n               <tr>\\n                <td>\\n                 $ratio \\\\leq 0.33$\\n                </td>\\n                <td>\\n                 absolutely disagrees\\n                </td>\\n               </tr>\\n              </tbody>\\n             </table>\\n            </div>\\n           </div>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Let\\'s make a function that replicates this logic:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">def get_agreeance_text(ratio):\\n    if ratio &gt; 3: return \"absolutely agrees\"\\n    elif 2 &lt; ratio &lt;= 3: return \"strongly agrees\"\\n    elif 1.5 &lt; ratio &lt;= 2: return \"agrees\"\\n    elif 1 &lt; ratio &lt;= 1.5: return \"somewhat agrees\"\\n    elif ratio == 1: return \"neutral\"\\n    elif 0.67 &lt; ratio &lt; 1: return \"somewhat disagrees\"\\n    elif 0.5 &lt; ratio &lt;= 0.67: return \"disagrees\"\\n    elif 0.33 &lt; ratio &lt;= 0.5: return \"strongly disagrees\"\\n    elif ratio &lt;= 0.33: return \"absolutely disagrees\"\\n    else: return None\\n    \\nprint(get_agreeance_text(2.5))</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed out-code\">\\n          <div class=\"out\">\\n           Out:\\n          </div>\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">strongly agrees</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Now that we have the general logic for a single row and we can generate the agreeance text, let\\'s create a loop that gets data from every row on the first page:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">data= []\\n\\nfor row in rows:\\n    d = dict()\\n    \\n    d[\\'name\\'] = row.select_one(\\'.source-title\\').text.strip()\\n    d[\\'allsides_page\\'] = \\'https://www.allsides.com\\' + row.select_one(\\'.source-title a\\')[\\'href\\']\\n    d[\\'bias\\'] = row.select_one(\\'.views-field-field-bias-image a\\')[\\'href\\'].split(\\'/\\')[-1]\\n    d[\\'agree\\'] = int(row.select_one(\\'.agree\\').text)\\n    d[\\'disagree\\'] = int(row.select_one(\\'.disagree\\').text)\\n    d[\\'agree_ratio\\'] = d[\\'agree\\'] / d[\\'disagree\\']\\n    d[\\'agreeance_text\\'] = get_agreeance_text(d[\\'agree_ratio\\'])\\n    \\n    data.append(d)</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            In the loop we can combine any multi-step extractions into one to create the values in the least number of steps.\\n           </p>\\n           <p>\\n            Our\\n            <code>\\n             data\\n            </code>\\n            list now contains a dictionary containing key information for every row.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">print(data[0])</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed out-code\">\\n          <div class=\"out\">\\n           Out:\\n          </div>\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">{\\'name\\': \\'ABC News\\', \\'allsides_page\\': \\'https://www.allsides.com/news-source/abc-news-media-bias\\', \\'bias\\': \\'left-center\\', \\'agree\\': 8411, \\'disagree\\': 6662, \\'agree_ratio\\': 1.2625337736415492, \\'agreeance_text\\': \\'somewhat agrees\\'}</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Keep in mind that\\n            <b>\\n             this is still only the first page\\n            </b>\\n            . The list on AllSides is three pages long as of this writing, so we need to modify this loop to get the other pages.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h3 id=\"Requestingandparsingmultiplepages\">\\n           Requesting and parsing multiple pages\\n          </h3>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            Notice that the URLs for each page follow a pattern. The first page has no parameters on the URL, but the next pages do; specifically they attach a\\n            <code>\\n             ?page=#\\n            </code>\\n            to the URL where \\'#\\' is the page number.\\n           </p>\\n           <p>\\n            Right now, the easiest way to get all pages is just to manually make a list of these three pages and loop over them. If we were working on a project with thousands of pages we might build a more automated way of constructing/finding the next URLs, but for now this works.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">pages = [\\n    \\'https://www.allsides.com/media-bias/media-bias-ratings\\',\\n    \\'https://www.allsides.com/media-bias/media-bias-ratings?page=1\\',\\n    \\'https://www.allsides.com/media-bias/media-bias-ratings?page=2\\'\\n]</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            According to AllSides\\'\\n            <i>\\n             robots.txt\\n            </i>\\n            we need to make sure we wait ten seconds before each request.\\n           </p>\\n           <p>\\n            Our loop will:\\n           </p>\\n           <ul>\\n            <li>\\n             request a page\\n            </li>\\n            <li>\\n             parse the page\\n            </li>\\n            <li>\\n             wait ten seconds\\n            </li>\\n            <li>\\n             repeat for next page.\\n            </li>\\n           </ul>\\n           <p>\\n            Remember, we\\'ve already tested our parsing above on a page that was cached locally so we know it works. You\\'ll want to make sure to do this\\n            <b>\\n             before\\n            </b>\\n            making a loop that performs requests to prevent having to reloop if you forgot to parse something.\\n           </p>\\n           <p>\\n            By combining all the steps we\\'ve done up to this point and adding a loop over pages, here\\'s how it looks:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">from time import sleep\\n\\ndata= []\\n\\nfor page in pages:\\n    r = requests.get(page)\\n    soup = BeautifulSoup(r.content, \\'html.parser\\')\\n    \\n    rows = soup.select(\\'tbody tr\\')\\n\\n    for row in rows:\\n        d = dict()\\n\\n        d[\\'name\\'] = row.select_one(\\'.source-title\\').text.strip()\\n        d[\\'allsides_page\\'] = \\'https://www.allsides.com\\' + row.select_one(\\'.source-title a\\')[\\'href\\']\\n        d[\\'bias\\'] = row.select_one(\\'.views-field-field-bias-image a\\')[\\'href\\'].split(\\'/\\')[-1]\\n        d[\\'agree\\'] = int(row.select_one(\\'.agree\\').text)\\n        d[\\'disagree\\'] = int(row.select_one(\\'.disagree\\').text)\\n        d[\\'agree_ratio\\'] = d[\\'agree\\'] / d[\\'disagree\\']\\n        d[\\'agreeance_text\\'] = get_agreeance_text(d[\\'agree_ratio\\'])\\n\\n        data.append(d)\\n    \\n    sleep(10)</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            Now we have a list of dictionaries for each row on all three pages.\\n           </p>\\n           <p>\\n            To cap it off, we want to get the real URL to the news source, not just the link to their presence on AllSides. To do this, we will need to get the AllSides page and look for the link.\\n           </p>\\n           <p>\\n            If we go to\\n            <a href=\"https://www.allsides.com/news-source/abc-news-media-bias\">\\n             ABC News\\' page\\n            </a>\\n            there\\'s a row of external links to Facebook, Twitter, Wikipedia, and the ABC News website. The HTML for that sections looks like this:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/javascript\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-javascript\">&lt;div class=\"row-fluid source-links gray-bg-box\"&gt;\\n    &lt;div class=\"container\"&gt;    \\n        &lt;a href=\"https://www.facebook.com/ABCNews/\" class=\"facebook\"&gt;\\n            &lt;i class=\"fa fa-facebook\" aria-hidden=\"true\"&gt;&lt;/i&gt;&lt;span&gt;Facebook&lt;/span&gt;\\n        &lt;/a&gt;\\n        &lt;a href=\"https://twitter.com/ABC\" class=\"twitter\"&gt;\\n            &lt;i class=\"fa fa-twitter\" aria-hidden=\"true\"&gt;&lt;/i&gt;\\n            &lt;span&gt;Twitter&lt;/span&gt;\\n        &lt;/a&gt;\\n        &lt;a href=\"https://en.wikipedia.org/wiki/ABC_News\" class=\"wikipedia\"&gt;\\n            &lt;i class=\"fa fa-wikipedia-w\" aria-hidden=\"true\"&gt;&lt;/i&gt;\\n            &lt;span&gt;Wikipedia&lt;/span&gt;\\n        &lt;/a&gt;\\n        &lt;a href=\"http://abcnews.go.com/\" class=\"www\"&gt;&lt;i class=\"fa fa-globe\" aria-hidden=\"true\"&gt;\\n            &lt;/i&gt;&lt;span&gt;ABC News&lt;/span&gt;\\n        &lt;/a&gt;\\n        &lt;a href=\"/contact\" class=\"improve-this-page\"&gt;\\n            &lt;i class=\"fa fa-line-chart\" aria-hidden=\"true\"&gt;&lt;/i&gt;\\n            &lt;span&gt;Improve this page&lt;/span&gt;\\n        &lt;/a&gt;\\n    &lt;/div&gt;\\n&lt;/div&gt;</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Notice the anchor tag (\\n            <code>\\n             &lt;a&gt;\\n            </code>\\n            ) that contains the link to ABC News has a class of \"www\". Pretty easy to get with what we\\'ve already learned:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">website = soup.select_one(\\'.www\\')[\\'href\\']</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            So let\\'s make another loop to request the AllSides page and get links for each news source. Unfortunately, some pages don\\'t have a link in this grey bar to the news source, which brings up a good point:\\n            <b>\\n             always account for elements to randomly not exist\\n            </b>\\n            .\\n           </p>\\n           <p>\\n            Up until now we\\'ve assumed elements exist in the tables we scraped, but it\\'s always a good idea to program scrapers in way so they don\\'t break when an element goes missing.\\n           </p>\\n           <p>\\n            Using\\n            <code>\\n             select_one\\n            </code>\\n            or\\n            <code>\\n             select\\n            </code>\\n            will always return None or an empty list if nothing is found, so in this loop we\\'ll check if we found the website element or not so it doesn\\'t throw an Exception when trying to access the\\n            <code>\\n             href\\n            </code>\\n            attribute.\\n           </p>\\n           <p>\\n            Finally, since there\\'s 265 news source pages and the wait time between pages is 10 seconds, it\\'s going to take ~44 minutes to do this. Instead of blindly not knowing our progress, let\\'s use the\\n            <code>\\n             tqdm\\n            </code>\\n            library (\\n            <code>\\n             pip install tqdm\\n            </code>\\n            ) to give us a nice progress bar:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">from copy import deepcopy\\nfrom tqdm import tqdm_notebook\\n\\nfor d in tqdm_notebook(data):\\n    r = requests.get(d[\\'allsides_page\\'])\\n    soup = BeautifulSoup(r.content, \\'html.parser\\')\\n    \\n    try:\\n        website = soup.select_one(\\'.www\\')[\\'href\\']\\n        d[\\'website\\'] = website\\n    except TypeError:\\n        pass\\n    \\n    sleep(10)</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <img src=\"https://www.learndatasci.com/documents/18/progress_bar.gif\"/>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            <code>\\n             tqdm\\n            </code>\\n            is a little weird at first, but essentially\\n            <code>\\n             tqdm_notebook\\n            </code>\\n            is just wrapping around our data list to produce a progress bar. We are still able to access each dictionary,\\n            <code>\\n             d\\n            </code>\\n            , just as we would normally. Note that\\n            <code>\\n             tqdm_notebook\\n            </code>\\n            is only for Jupyter notebooks. In regular editors you\\'ll just\\n            <code>\\n             import tqdm from tqdm\\n            </code>\\n            and use\\n            <code>\\n             tqdm\\n            </code>\\n            instead.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h3 id=\"Savingourdata\">\\n           Saving our data\\n          </h3>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            So what do we have now? At this moment,\\n            <code>\\n             data\\n            </code>\\n            is a list of dictionaries, each of which contains all the data from the tables as well as the websites from each individual news source\\'s page on AllSides.\\n           </p>\\n           <p>\\n            The first thing we\\'ll want to do now is save that data to a file so we don\\'t have to make those requests again. We\\'ll be storing the data as JSON since it\\'s already in that form anyway:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">import json\\n\\nwith open(\\'allsides.json\\', \\'w\\') as f:\\n    json.dump(data, f)</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            To load it back in when you need it:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">with open(\\'allsides.json\\', \\'r\\') as f:\\n    data = json.load(f)</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            If you\\'re not familiar with JSON, just quickly open\\n            <code>\\n             allsides.json\\n            </code>\\n            in an editor and see what it looks like. It should look almost exactly like what\\n            <code>\\n             data\\n            </code>\\n            looks like if we print it in Python: a list of dictionaries.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h2 id=\"BriefDataAnalysis\">\\n           Brief Data Analysis\\n          </h2>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Before ending this article I think it would be worthwhile to actually see what\\'s interesting about this data we just retrieved. So, let\\'s answer a couple of questions.\\n           </p>\\n           <p>\\n            <b>\\n             Which ratings for outlets does the community\\n            </b>\\n            <b>\\n             <i>\\n              absolutely agree\\n             </i>\\n            </b>\\n            <b>\\n             on?\\n            </b>\\n           </p>\\n           <p>\\n            To find where the community absolutely agrees we can do a simple list comprehension that checks each\\n            <code>\\n             dict\\n            </code>\\n            for the agreeance text we want:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">abs_agree = [d for d in data if d[\\'agreeance_text\\'] == \\'absolutely agrees\\']\\n\\nprint(f\"{\\'Outlet\\':&lt;20} {\\'Bias\\':&lt;20}\")\\nprint(\"-\" * 30)\\n\\nfor d in abs_agree:\\n    print(f\"{d[\\'name\\']:&lt;20} {d[\\'bias\\']:&lt;20}\")</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed out-code\">\\n          <div class=\"out\">\\n           Out:\\n          </div>\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">Outlet               Bias                \\n------------------------------\\nC-SPAN               center              \\nCurrent Affairs      left                \\nInfoWars             right               \\nJacobin              left                \\nMashable             left                \\nMother Jones         left                \\nPoliticusUSA         left                \\nRed State            right               \\nRollingStone.com     left                \\nSplinter             left                \\nThe Daily Signal     right               \\nVice                 left</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Using some string formatting we can make it look somewhat tabular. Interestingly,\\n            <i>\\n             C-SPAN\\n            </i>\\n            is the only center bias that the community absolutely agrees on. The others for left and right aren\\'t that surprising.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h3 id=\"MakinganalysiseasierwithPandas\">\\n           Making analysis easier with Pandas\\n          </h3>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            <b>\\n             Which ratings for outlets does the community\\n            </b>\\n            <b>\\n             <i>\\n              absolutely disagree\\n             </i>\\n            </b>\\n            <b>\\n             on?\\n            </b>\\n           </p>\\n           <p>\\n            To make analysis a little easier, we can also load our JSON data into a Pandas DataFrame as well. This is easy with Pandas since they have a simple function for reading JSON into a DataFrame.\\n           </p>\\n           <p>\\n            As an aside, if you\\'ve never used Pandas (\\n            <code>\\n             pip install pandas\\n            </code>\\n            ), Matplotlib (\\n            <code>\\n             pip install matplotlib\\n            </code>\\n            ), or any of the other data science libraries, I would definitely recommend checking out\\n            <a href=\"/out/udemy-python-for-data-science-and-machine-learning-bootcamp/\">\\n             Jose Portilla\\'s data science course\\n            </a>\\n            for a great intro to these tools and many machine learning concepts.\\n           </p>\\n           <p>\\n            Now to the DataFrame:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">import pandas as pd\\n\\ndf = pd.read_json(open(\\'allsides.json\\', \\'r\\'))\\n\\ndf.set_index(\\'name\\', inplace=True)\\n\\ndf.head()</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"\">\\n          <div class=\"table-block table-style-default out-table\">\\n           <div class=\"out\">\\n            Out:\\n           </div>\\n           <div class=\"tbl-wrap fullwidth-wrap\">\\n            <div class=\"scrollable\">\\n             <table border=\"1\" class=\"dataframe\">\\n              <thead>\\n               <tr style=\"text-align: right;\">\\n                <th>\\n                </th>\\n                <th>\\n                 agree\\n                </th>\\n                <th>\\n                 agree_ratio\\n                </th>\\n                <th>\\n                 agreeance_text\\n                </th>\\n                <th>\\n                 allsides_page\\n                </th>\\n                <th>\\n                 bias\\n                </th>\\n                <th>\\n                 disagree\\n                </th>\\n               </tr>\\n               <tr>\\n                <th>\\n                 name\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n               </tr>\\n              </thead>\\n              <tbody>\\n               <tr>\\n                <th>\\n                 ABC News\\n                </th>\\n                <td>\\n                 8355\\n                </td>\\n                <td>\\n                 1.260371\\n                </td>\\n                <td>\\n                 somewhat agrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/abc-news-...\\n                </td>\\n                <td>\\n                 left-center\\n                </td>\\n                <td>\\n                 6629\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 Al Jazeera\\n                </th>\\n                <td>\\n                 1996\\n                </td>\\n                <td>\\n                 0.694986\\n                </td>\\n                <td>\\n                 somewhat disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/al-jazeer...\\n                </td>\\n                <td>\\n                 center\\n                </td>\\n                <td>\\n                 2872\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 AllSides\\n                </th>\\n                <td>\\n                 2615\\n                </td>\\n                <td>\\n                 2.485741\\n                </td>\\n                <td>\\n                 strongly agrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/allsides-0\\n                </td>\\n                <td>\\n                 allsides\\n                </td>\\n                <td>\\n                 1052\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 AllSides Community\\n                </th>\\n                <td>\\n                 1760\\n                </td>\\n                <td>\\n                 1.668246\\n                </td>\\n                <td>\\n                 agrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/allsides-...\\n                </td>\\n                <td>\\n                 allsides\\n                </td>\\n                <td>\\n                 1055\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 AlterNet\\n                </th>\\n                <td>\\n                 1226\\n                </td>\\n                <td>\\n                 2.181495\\n                </td>\\n                <td>\\n                 strongly agrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/alternet\\n                </td>\\n                <td>\\n                 left\\n                </td>\\n                <td>\\n                 562\\n                </td>\\n               </tr>\\n              </tbody>\\n             </table>\\n            </div>\\n           </div>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Now filter the DataFrame by \"agreeance_text\":\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">df[df[\\'agreeance_text\\'] == \\'strongly disagrees\\']</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"\">\\n          <div class=\"table-block table-style-default out-table\">\\n           <div class=\"out\">\\n            Out:\\n           </div>\\n           <div class=\"tbl-wrap fullwidth-wrap\">\\n            <div class=\"scrollable\">\\n             <table border=\"1\" class=\"dataframe\">\\n              <thead>\\n               <tr style=\"text-align: right;\">\\n                <th>\\n                </th>\\n                <th>\\n                 agree\\n                </th>\\n                <th>\\n                 agree_ratio\\n                </th>\\n                <th>\\n                 agreeance_text\\n                </th>\\n                <th>\\n                 allsides_page\\n                </th>\\n                <th>\\n                 bias\\n                </th>\\n                <th>\\n                 disagree\\n                </th>\\n               </tr>\\n               <tr>\\n                <th>\\n                 name\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n               </tr>\\n              </thead>\\n              <tbody>\\n               <tr>\\n                <th>\\n                 CNBC\\n                </th>\\n                <td>\\n                 1239\\n                </td>\\n                <td>\\n                 0.398905\\n                </td>\\n                <td>\\n                 strongly disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/cnbc\\n                </td>\\n                <td>\\n                 center\\n                </td>\\n                <td>\\n                 3106\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 Quillette\\n                </th>\\n                <td>\\n                 45\\n                </td>\\n                <td>\\n                 0.416667\\n                </td>\\n                <td>\\n                 strongly disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/quillette...\\n                </td>\\n                <td>\\n                 right-center\\n                </td>\\n                <td>\\n                 108\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 The Courier-Journal\\n                </th>\\n                <td>\\n                 64\\n                </td>\\n                <td>\\n                 0.410256\\n                </td>\\n                <td>\\n                 strongly disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/courier-j...\\n                </td>\\n                <td>\\n                 left-center\\n                </td>\\n                <td>\\n                 156\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 The Economist\\n                </th>\\n                <td>\\n                 779\\n                </td>\\n                <td>\\n                 0.485964\\n                </td>\\n                <td>\\n                 strongly disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/economist\\n                </td>\\n                <td>\\n                 left-center\\n                </td>\\n                <td>\\n                 1603\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 The Observer (New York)\\n                </th>\\n                <td>\\n                 123\\n                </td>\\n                <td>\\n                 0.484252\\n                </td>\\n                <td>\\n                 strongly disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/observer\\n                </td>\\n                <td>\\n                 center\\n                </td>\\n                <td>\\n                 254\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 The Oracle\\n                </th>\\n                <td>\\n                 33\\n                </td>\\n                <td>\\n                 0.485294\\n                </td>\\n                <td>\\n                 strongly disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/oracle\\n                </td>\\n                <td>\\n                 center\\n                </td>\\n                <td>\\n                 68\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 The Republican\\n                </th>\\n                <td>\\n                 108\\n                </td>\\n                <td>\\n                 0.392727\\n                </td>\\n                <td>\\n                 strongly disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/republican\\n                </td>\\n                <td>\\n                 center\\n                </td>\\n                <td>\\n                 275\\n                </td>\\n               </tr>\\n              </tbody>\\n             </table>\\n            </div>\\n           </div>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            It looks like much of the community disagrees strongly with certain outlets being rated with a \"center\" bias.\\n           </p>\\n           <p>\\n            Let\\'s make a quick visualization of agreeance. Since there\\'s too many news sources to plot so let\\'s pull only those with the most votes. To do that, we can make a new column that counts the total votes and then sort by that value:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">df[\\'total_votes\\'] = df[\\'agree\\'] + df[\\'disagree\\']\\ndf.sort_values(\\'total_votes\\', ascending=False, inplace=True)\\n\\ndf.head(10)</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"\">\\n          <div class=\"table-block table-style-default out-table\">\\n           <div class=\"out\">\\n            Out:\\n           </div>\\n           <div class=\"tbl-wrap fullwidth-wrap\">\\n            <div class=\"scrollable\">\\n             <table border=\"1\" class=\"dataframe\">\\n              <thead>\\n               <tr style=\"text-align: right;\">\\n                <th>\\n                </th>\\n                <th>\\n                 agree\\n                </th>\\n                <th>\\n                 agree_ratio\\n                </th>\\n                <th>\\n                 agreeance_text\\n                </th>\\n                <th>\\n                 allsides_page\\n                </th>\\n                <th>\\n                 bias\\n                </th>\\n                <th>\\n                 disagree\\n                </th>\\n                <th>\\n                 total_votes\\n                </th>\\n               </tr>\\n               <tr>\\n                <th>\\n                 name\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n               </tr>\\n              </thead>\\n              <tbody>\\n               <tr>\\n                <th>\\n                 CNN (Web News)\\n                </th>\\n                <td>\\n                 22907\\n                </td>\\n                <td>\\n                 0.970553\\n                </td>\\n                <td>\\n                 somewhat disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/cnn-media...\\n                </td>\\n                <td>\\n                 left-center\\n                </td>\\n                <td>\\n                 23602\\n                </td>\\n                <td>\\n                 46509\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 Fox News\\n                </th>\\n                <td>\\n                 17410\\n                </td>\\n                <td>\\n                 0.650598\\n                </td>\\n                <td>\\n                 disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/fox-news-...\\n                </td>\\n                <td>\\n                 right-center\\n                </td>\\n                <td>\\n                 26760\\n                </td>\\n                <td>\\n                 44170\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 Washington Post\\n                </th>\\n                <td>\\n                 21434\\n                </td>\\n                <td>\\n                 1.682022\\n                </td>\\n                <td>\\n                 agrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/washingto...\\n                </td>\\n                <td>\\n                 left-center\\n                </td>\\n                <td>\\n                 12743\\n                </td>\\n                <td>\\n                 34177\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 New York Times - News\\n                </th>\\n                <td>\\n                 12275\\n                </td>\\n                <td>\\n                 0.570002\\n                </td>\\n                <td>\\n                 disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/new-york-...\\n                </td>\\n                <td>\\n                 left-center\\n                </td>\\n                <td>\\n                 21535\\n                </td>\\n                <td>\\n                 33810\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 HuffPost\\n                </th>\\n                <td>\\n                 15056\\n                </td>\\n                <td>\\n                 0.834127\\n                </td>\\n                <td>\\n                 somewhat disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/huffpost-...\\n                </td>\\n                <td>\\n                 left\\n                </td>\\n                <td>\\n                 18050\\n                </td>\\n                <td>\\n                 33106\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 Politico\\n                </th>\\n                <td>\\n                 11047\\n                </td>\\n                <td>\\n                 0.598656\\n                </td>\\n                <td>\\n                 disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/politico-...\\n                </td>\\n                <td>\\n                 left-center\\n                </td>\\n                <td>\\n                 18453\\n                </td>\\n                <td>\\n                 29500\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 Washington Times\\n                </th>\\n                <td>\\n                 18934\\n                </td>\\n                <td>\\n                 2.017475\\n                </td>\\n                <td>\\n                 strongly agrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/washingto...\\n                </td>\\n                <td>\\n                 right-center\\n                </td>\\n                <td>\\n                 9385\\n                </td>\\n                <td>\\n                 28319\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 NPR News\\n                </th>\\n                <td>\\n                 15751\\n                </td>\\n                <td>\\n                 1.481889\\n                </td>\\n                <td>\\n                 somewhat agrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/npr-media...\\n                </td>\\n                <td>\\n                 center\\n                </td>\\n                <td>\\n                 10629\\n                </td>\\n                <td>\\n                 26380\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 Wall Street Journal - News\\n                </th>\\n                <td>\\n                 9872\\n                </td>\\n                <td>\\n                 0.627033\\n                </td>\\n                <td>\\n                 disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/wall-stre...\\n                </td>\\n                <td>\\n                 center\\n                </td>\\n                <td>\\n                 15744\\n                </td>\\n                <td>\\n                 25616\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 Townhall\\n                </th>\\n                <td>\\n                 7632\\n                </td>\\n                <td>\\n                 0.606967\\n                </td>\\n                <td>\\n                 disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/townhall-...\\n                </td>\\n                <td>\\n                 right\\n                </td>\\n                <td>\\n                 12574\\n                </td>\\n                <td>\\n                 20206\\n                </td>\\n               </tr>\\n              </tbody>\\n             </table>\\n            </div>\\n           </div>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h4 id=\"Visualiingthedata\">\\n           Visualizing the data\\n          </h4>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            To make a bar plot we\\'ll use Matplotlib with Seaborn\\'s dark grid style:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">import matplotlib.pyplot as plt\\nplt.style.use(\\'seaborn-darkgrid\\')</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            As mentioned above, we have too many news outlets to plot comfortably, so just make a copy of the top 25 and place it in a new\\n            <code>\\n             df2\\n            </code>\\n            variable:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">df2 = df.head(25).copy()\\n\\ndf2.head()</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"\">\\n          <div class=\"table-block table-style-default out-table\">\\n           <div class=\"out\">\\n            Out:\\n           </div>\\n           <div class=\"tbl-wrap fullwidth-wrap\">\\n            <div class=\"scrollable\">\\n             <table border=\"1\" class=\"dataframe\">\\n              <thead>\\n               <tr style=\"text-align: right;\">\\n                <th>\\n                </th>\\n                <th>\\n                 agree\\n                </th>\\n                <th>\\n                 agree_ratio\\n                </th>\\n                <th>\\n                 agreeance_text\\n                </th>\\n                <th>\\n                 allsides_page\\n                </th>\\n                <th>\\n                 bias\\n                </th>\\n                <th>\\n                 disagree\\n                </th>\\n                <th>\\n                 total_votes\\n                </th>\\n               </tr>\\n               <tr>\\n                <th>\\n                 name\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n                <th>\\n                </th>\\n               </tr>\\n              </thead>\\n              <tbody>\\n               <tr>\\n                <th>\\n                 CNN (Web News)\\n                </th>\\n                <td>\\n                 22907\\n                </td>\\n                <td>\\n                 0.970553\\n                </td>\\n                <td>\\n                 somewhat disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/cnn-media...\\n                </td>\\n                <td>\\n                 left-center\\n                </td>\\n                <td>\\n                 23602\\n                </td>\\n                <td>\\n                 46509\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 Fox News\\n                </th>\\n                <td>\\n                 17410\\n                </td>\\n                <td>\\n                 0.650598\\n                </td>\\n                <td>\\n                 disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/fox-news-...\\n                </td>\\n                <td>\\n                 right-center\\n                </td>\\n                <td>\\n                 26760\\n                </td>\\n                <td>\\n                 44170\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 Washington Post\\n                </th>\\n                <td>\\n                 21434\\n                </td>\\n                <td>\\n                 1.682022\\n                </td>\\n                <td>\\n                 agrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/washingto...\\n                </td>\\n                <td>\\n                 left-center\\n                </td>\\n                <td>\\n                 12743\\n                </td>\\n                <td>\\n                 34177\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 New York Times - News\\n                </th>\\n                <td>\\n                 12275\\n                </td>\\n                <td>\\n                 0.570002\\n                </td>\\n                <td>\\n                 disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/new-york-...\\n                </td>\\n                <td>\\n                 left-center\\n                </td>\\n                <td>\\n                 21535\\n                </td>\\n                <td>\\n                 33810\\n                </td>\\n               </tr>\\n               <tr>\\n                <th>\\n                 HuffPost\\n                </th>\\n                <td>\\n                 15056\\n                </td>\\n                <td>\\n                 0.834127\\n                </td>\\n                <td>\\n                 somewhat disagrees\\n                </td>\\n                <td>\\n                 https://www.allsides.com/news-source/huffpost-...\\n                </td>\\n                <td>\\n                 left\\n                </td>\\n                <td>\\n                 18050\\n                </td>\\n                <td>\\n                 33106\\n                </td>\\n               </tr>\\n              </tbody>\\n             </table>\\n            </div>\\n           </div>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            With the top 25 news sources by amount of feedback, let\\'s create a stacked bar chart where the number of\\n            <i>\\n             agrees\\n            </i>\\n            are stacked on top of the number of\\n            <i>\\n             disagrees\\n            </i>\\n            . This makes the total height of the bar the total amount of feedback.\\n           </p>\\n           <p>\\n            Below, we first create a figure and axes, plot the agree bars, plot the disagree bars on top of the agrees using\\n            <code>\\n             bottom\\n            </code>\\n            , then set various text features:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">fig, ax = plt.subplots(figsize=(20, 10))\\n\\nax.bar(df2.index, df2[\\'agree\\'], color=\\'#5DAF83\\')\\nax.bar(df2.index, df2[\\'disagree\\'], bottom=df2[\\'agree\\'], color=\\'#AF3B3B\\')\\n\\nax.set_ylabel = \\'Total feedback\\'\\n\\nplt.yticks(fontsize=\\'x-large\\')\\nplt.xticks(rotation=60, ha=\\'right\\', fontsize=\\'x-large\\', rotation_mode=\\'anchor\\')\\n\\nplt.legend([\\'Agree\\', \\'Disagree\\'], fontsize=\\'xx-large\\')\\nplt.title(\\'AllSides Bias Rating vs. Community Feedback\\', fontsize=\\'xx-large\\')\\nplt.show()</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"output-image\">\\n          <figure class=\"output-images fullwidth-wrap\">\\n           <div class=\"out-tag\">\\n            RESULT:\\n           </div>\\n           <div class=\"attributed-wrap\">\\n            <img class=\"img-responsive\" height=\"761\" loading=\"lazy\" src=\"https://storage.googleapis.com/lds-media/images/allsides_bias_rating_vs_community_feedback.width-1200.png\" width=\"1200\"/>\\n           </div>\\n          </figure>\\n          <a class=\"zoom-in-img\" href=\"https://storage.googleapis.com/lds-media/images/allsides_bias_rating_vs_community_feedback.width-1200.png\" target=\"_blank\">\\n           <svg enable-background=\"new 0 0 24 24\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\">\\n            <rect fill=\"none\" height=\"24\" width=\"24\">\\n            </rect>\\n            <polygon points=\"21,11 21,3 13,3 16.29,6.29 6.29,16.29 3,13 3,21 11,21 7.71,17.71 17.71,7.71\">\\n            </polygon>\\n           </svg>\\n          </a>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n           </p>\\n           <p>\\n            For a slightly more complex version, let\\'s make a subplot for each bias and plot the respective news sources.\\n           </p>\\n           <p>\\n            This time we\\'ll make a new copy of the original DataFrame beforehand since we can plot more news outlets now.\\n           </p>\\n           <p>\\n            Instead of making one axes, we\\'ll create a new one for each bias to make six total subplots:\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"code-embed\">\\n          <pre><code ace-gutter=\"false\" ace-mode=\"ace/mode/python\" ace-theme=\"ace/theme/tomorrow\" class=\"pretty-code prettyprint language-python\">df3 = df.copy()\\n\\nfig = plt.figure(figsize=(15,15))\\n\\nbiases = df3[\\'bias\\'].unique()\\n\\nfor i, bias in enumerate(biases):\\n    # Get top 10 news sources for this bias and sort index alphabetically\\n    temp_df = df3[df3[\\'bias\\'] == bias].iloc[:10]\\n    temp_df.sort_index(inplace=True)\\n    \\n    # Get max votes, i.e. the y value for tallest bar in this temp dataframe\\n    max_votes = temp_df[\\'total_votes\\'].max()\\n    \\n    # Add a new subplot in the correct grid position\\n    ax = fig.add_subplot(len(biases) / 2, 2, i + 1)\\n    \\n    # Create the stacked bars\\n    ax.bar(temp_df.index, temp_df[\\'agree\\'], color=\\'#5DAF83\\')\\n    ax.bar(temp_df.index, temp_df[\\'disagree\\'], bottom=temp_df[\\'agree\\'], color=\\'#AF3B3B\\')\\n    \\n    # Place text for the ratio on top of each bar\\n    for x, y, ratio in zip(ax.get_xticks(), temp_df[\\'total_votes\\'], temp_df[\\'agree_ratio\\']):\\n        ax.text(x, y + (0.02 * max_votes), f\"{ratio:.2f}\", ha=\\'center\\')\\n    \\n    ax.set_ylabel(\\'Total feedback\\')\\n    ax.set_title(bias.title())\\n    \\n    # Make y limit larger to compensate for text on bars\\n    ax.set_ylim(0, max_votes + (0.12 * max_votes))\\n    \\n    # Rotate tick labels so they don\\'t overlap\\n    plt.setp(ax.get_xticklabels(), rotation=30, ha=\\'right\\')\\n\\nplt.tight_layout(w_pad=3.0, h_pad=1.0)\\nplt.show()</code></pre>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"output-image\">\\n          <figure class=\"output-images fullwidth-wrap\">\\n           <div class=\"out-tag\">\\n            RESULT:\\n           </div>\\n           <div class=\"attributed-wrap\">\\n            <img class=\"img-responsive\" height=\"1064\" loading=\"lazy\" src=\"https://storage.googleapis.com/lds-media/images/allsides_bias_rating_vs_community_feedback_-_.width-1200.png\" width=\"1063\"/>\\n           </div>\\n          </figure>\\n          <a class=\"zoom-in-img\" href=\"https://storage.googleapis.com/lds-media/images/allsides_bias_rating_vs_community_feedback_-_.width-1200.png\" target=\"_blank\">\\n           <svg enable-background=\"new 0 0 24 24\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\">\\n            <rect fill=\"none\" height=\"24\" width=\"24\">\\n            </rect>\\n            <polygon points=\"21,11 21,3 13,3 16.29,6.29 6.29,16.29 3,13 3,21 11,21 7.71,17.71 17.71,7.71\">\\n            </polygon>\\n           </svg>\\n          </a>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            Hopefully the comments help with how these plots were created. We\\'re just looping through each unique bias and adding a subplot to the figure.\\n           </p>\\n           <p>\\n            When interpreting these plots keep in mind that the y-axis has different scales for each subplot. Overall it\\'s a nice way to see which outlets have a lot of votes and where the most disagreement is. This is what makes scraping so much fun!\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"headers read-friendly\">\\n          <h2 id=\"Finalwords\">\\n           Final words\\n          </h2>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"paragraph read-friendly\">\\n          <div class=\"rich-text\">\\n           <p>\\n            We have the tools to make some fairly complex web scrapers now, but there\\'s still the issue with Javascript rendering. This is something that deserves its own article, but for now we can do quite a lot.\\n           </p>\\n           <p>\\n            There\\'s also some project organization that needs to occur when making this into a more easily runnable program. We need to pull it out of this notebook and code in command-line arguments if we plan to run it often for updates.\\n           </p>\\n           <p>\\n            These sorts of things will be addressed later when we build more complex scrapers, but feel free to let me know in the comments of anything in particular you\\'re interested in learning about.\\n           </p>\\n          </div>\\n         </div>\\n        </section>\\n        <section>\\n         <div class=\"highlight-note style-reference\">\\n          <h4>\\n           Resources\\n          </h4>\\n          <p>\\n          </p>\\n          <div class=\"rich-text\">\\n           <p>\\n            <a href=\"/out/amazon-web-scraping-python-2nd-ed/\">\\n             Web Scraping with Python: Collecting More Data from the Modern Web\\n            </a>\\n            â€” Book on Amazon\\n           </p>\\n           <p>\\n           </p>\\n           <p>\\n            <a href=\"/out/udemy-python-for-data-science-and-machine-learning-bootcamp/\">\\n             Jose Portilla\\'s Data Science and ML Bootcamp\\n            </a>\\n            â€” Course on Udemy\\n           </p>\\n           <p>\\n            Easiest way to get started with Data Science. Covers Pandas, Matplotlib, Seaborn, Scikit-learn, and a lot of other useful topics.\\n           </p>\\n          </div>\\n          <p>\\n          </p>\\n         </div>\\n        </section>\\n        <section>\\n         <iframe frameborder=\"0\" height=\"598\" marginheight=\"0\" marginwidth=\"0\" src=\"https://docs.google.com/forms/d/e/1FAIpQLSfkGRTnCtPn4ORh2DIlTgP9jfNJ0VJ2Rv03TkAuub06a7v87A/viewform?embedded=true\" width=\"640\">\\n          Loading...\\n         </iframe>\\n        </section>\\n       </div>\\n       <div class=\"index-wrapper\">\\n        <div class=\"ad\">\\n         <span>\\n          Take the internet\\'s best data science courses\\n         </span>\\n         <a href=\"/best-data-science-online-courses/\">\\n          Learn More\\n         </a>\\n        </div>\\n        <div class=\"sidebar-block newsletter\">\\n         <div class=\"newsletter-signup-wrapper\">\\n          <div id=\"mc_embed_signup\">\\n           <h3>\\n            Get updates in your inbox\\n           </h3>\\n           <p>\\n            Join over 7,500 data science learners.\\n           </p>\\n           <form action=\"https://learndatasci.us11.list-manage.com/subscribe/post?u=789c60e0c020546463993f85b&amp;id=f53d7286eb\" class=\"validate\" id=\"mc-embedded-subscribe-form\" method=\"post\" name=\"mc-embedded-subscribe-form\" novalidate=\"\" target=\"_blank\">\\n            <div id=\"mc_embed_signup_scroll\">\\n             <input class=\"required email\" id=\"mce-EMAIL\" name=\"EMAIL\" placeholder=\"Enter your email\" type=\"email\" value=\"\"/>\\n             <div class=\"clear\" id=\"mce-responses\">\\n              <div class=\"response\" id=\"mce-error-response\" style=\"display:none\">\\n              </div>\\n              <div class=\"response\" id=\"mce-success-response\" style=\"display:none\">\\n              </div>\\n             </div>\\n             <div aria-hidden=\"true\" style=\"position: absolute; left: -5000px;\">\\n              <input name=\"b_789c60e0c020546463993f85b_f53d7286eb\" tabindex=\"-1\" type=\"text\" value=\"\"/>\\n             </div>\\n             <input class=\"button\" id=\"mc-embedded-subscribe\" name=\"subscribe\" type=\"submit\" value=\"Subscribe\"/>\\n            </div>\\n           </form>\\n          </div>\\n         </div>\\n        </div>\\n        <div class=\"sidebar-block\">\\n         <h3>\\n          Recent articles:\\n         </h3>\\n         <a href=\"/glossary/sigmoid-function/\">\\n          <h5>\\n           Sigmoid Function\\n          </h5>\\n         </a>\\n         <a href=\"/glossary/dot-product/\">\\n          <h5>\\n           Dot Product\\n          </h5>\\n         </a>\\n         <a href=\"/best-artificial-intelligence-ai-courses/\">\\n          <h5>\\n           7 Best Artificial Intelligence (AI) Courses for 2022\\n          </h5>\\n         </a>\\n         <a href=\"/best-programming-and-coding-courses/\">\\n          <h5>\\n           5 Best Programming and Coding Courses for 2022: Beginner\\'s Guide\\n          </h5>\\n         </a>\\n        </div>\\n        <div data-link=\"/best-python-courses\" id=\"TrendingArticle\" style=\"display:none;\">\\n         <div class=\"article-block\">\\n          <div class=\"feat-img\" style=\"background-image:url(\\'https://storage.googleapis.com/lds-media/images/best-python-courses-by-interaction.2e16d0ba.fill-800x160.png\\');\">\\n          </div>\\n          <h1>\\n           Best Python courses according to data analysis\\n          </h1>\\n          <p>\\n           Out of roughly 3000 offerings, these are the best Python courses according to this analysis.\\n          </p>\\n          <a class=\"trending-link btn\" href=\"/best-python-courses\">\\n           View article\\n          </a>\\n         </div>\\n        </div>\\n       </div>\\n      </div>\\n     </div>\\n     <div id=\"ArticleFoot\">\\n     </div>\\n     <section style=\"padding-top:0px;\">\\n      <hr/>\\n      <div class=\"newsletter-signup-blog in-content-newsletter\">\\n       <div class=\"newsletter-signup-wrapper\">\\n        <div id=\"mc_embed_signup\">\\n         <h3>\\n          Get updates in your inbox\\n         </h3>\\n         <p>\\n          Join over 7,500 data science learners.\\n         </p>\\n         <form action=\"https://learndatasci.us11.list-manage.com/subscribe/post?u=789c60e0c020546463993f85b&amp;id=f53d7286eb\" class=\"validate\" id=\"mc-embedded-subscribe-form\" method=\"post\" name=\"mc-embedded-subscribe-form\" novalidate=\"\" target=\"_blank\">\\n          <div id=\"mc_embed_signup_scroll\">\\n           <input class=\"required email\" id=\"mce-EMAIL\" name=\"EMAIL\" placeholder=\"Enter your email\" type=\"email\" value=\"\"/>\\n           <div class=\"clear\" id=\"mce-responses\">\\n            <div class=\"response\" id=\"mce-error-response\" style=\"display:none\">\\n            </div>\\n            <div class=\"response\" id=\"mce-success-response\" style=\"display:none\">\\n            </div>\\n           </div>\\n           <div aria-hidden=\"true\" style=\"position: absolute; left: -5000px;\">\\n            <input name=\"b_789c60e0c020546463993f85b_f53d7286eb\" tabindex=\"-1\" type=\"text\" value=\"\"/>\\n           </div>\\n           <input class=\"button\" id=\"mc-embedded-subscribe\" name=\"subscribe\" type=\"submit\" value=\"Subscribe\"/>\\n          </div>\\n         </form>\\n        </div>\\n       </div>\\n      </div>\\n     </section>\\n     <section class=\"full-width\" id=\"AuthorDetails\">\\n      <h3>\\n       Meet the Authors\\n      </h3>\\n      <div class=\"clearfix author-block\">\\n       <a href=\"/author/brendan\" style=\"text-decoration:none;\">\\n        <img alt=\"Brendan Martin\" class=\"author-lg-img\" height=\"300\" src=\"https://storage.googleapis.com/lds-media/images/Brendan-Martin.width-300.jpg\" width=\"300\"/>\\n       </a>\\n       <div>\\n        <a href=\"/author/brendan\" style=\"text-decoration:none;\">\\n         <b class=\"auth-name\">\\n          Brendan Martin\\n         </b>\\n        </a>\\n        <a href=\"/author/brendan\" style=\"text-decoration:none;\">\\n         <b class=\"auth-title\">\\n          Founder of LearnDataSci\\n         </b>\\n        </a>\\n       </div>\\n       <div class=\"rich-text\">\\n        <p>\\n         Author and Editor at LearnDataSci. Python development and data science consultant.\\n        </p>\\n       </div>\\n      </div>\\n      <div style=\"display:block;\">\\n       <div class=\"editor-block clearfix\" style=\"max-width:700px;margin:0 auto;\">\\n       </div>\\n      </div>\\n     </section>\\n     <div class=\"back-to-idx\" style=\"margin-top:60px;\">\\n      <p>\\n       <a class=\"important-link\" href=\"/tutorials/\">\\n        Back to blog index\\n       </a>\\n      </p>\\n     </div>\\n    </article>\\n    <div class=\"container comments-wrap\" style=\"margin-top:60px;\">\\n    </div>\\n    <div class=\"comments-block\" style=\"text-align:center;\">\\n     <button id=\"show-comments\" onclick=\"disqus();return false;\" style=\"width: 740px;\\n    background-color: #fff1aa;\\n    color: black;\\n    max-width: 100%;\\n    border-color: black;\\n    border-width: 2px !important;\\n    border-style: solid;\">\\n      Load Comments\\n     </button>\\n    </div>\\n    <div style=\"max-width:720px;margin:0 auto;\">\\n     <div id=\"disqus_thread\">\\n     </div>\\n    </div>\\n    <script>\\n     let disqus_loaded = false;\\n            const disqus_shortname = \\'learn-data-sci\\'; //Add your shortname here\\n\\n            function disqus() {\\n\\n                if (!disqus_loaded) {\\n                    disqus_loaded = true;\\n\\n                    var e = document.createElement(\"script\");\\n                    e.type = \"text/javascript\";\\n                    e.async = true;\\n                    e.src = \"//\" + disqus_shortname + \".disqus.com/embed.js\";\\n                    (document.getElementsByTagName(\"head\")[0] ||\\n                        document.getElementsByTagName(\"body\")[0])\\n                        .appendChild(e);\\n\\n                    //Hide the button after opening\\n                    document.getElementById(\"show-comments\").style.display = \"none\";\\n                }\\n            }\\n\\n            //Opens comments when linked to directly\\n            let hash = window.location.hash.substr(1);\\n            if (hash.length > 8) {\\n                if (hash.substring(0, 8) == \"comment-\") {\\n                    disqus();\\n                }\\n            }\\n\\n            if (/bot|google|baidu|bing|msn|duckduckgo|slurp|yandex/i.test(navigator.userAgent)) {\\n                // Enable to allow comments for search engines\\n                // disqus();\\n            }\\n    </script>\\n   </div>\\n  </div>\\n  <div class=\"push\">\\n  </div>\\n  <footer class=\"footer\" id=\"footer\">\\n   <div class=\"footer-share\">\\n    <li class=\"social-menu-icons\">\\n     <a alt=\"GitHub\" href=\"https://github.com/LearnDataSci\">\\n      <img src=\"https://storage.googleapis.com/lds-media/documents/github-ico.svg\" width=\"30\"/>\\n     </a>\\n    </li>\\n    <li class=\"social-menu-icons\">\\n     <a alt=\"Twitter\" href=\"http://twitter.com/learndatasci\">\\n      <img src=\"https://storage.googleapis.com/lds-media/documents/twitter_Gvy5lp8.svg\" width=\"30\"/>\\n     </a>\\n    </li>\\n   </div>\\n   <div class=\"foot-content\">\\n    <ul class=\"footer-links\">\\n     <li>\\n      <a href=\"/best-data-science-online-courses\">\\n       Best Data Science Courses\\n      </a>\\n     </li>\\n     <li>\\n      <a href=\"/best-machine-learning-courses\">\\n       Best Machine Learning Courses\\n      </a>\\n     </li>\\n     <li>\\n      <a href=\"/top-udemy-data-science-courses\">\\n       Best Udemy Courses\\n      </a>\\n     </li>\\n    </ul>\\n    <ul class=\"footer-links\">\\n     <li>\\n      <a href=\"/glossary\">\\n       Data Science &amp; Machine Learning Glossary\\n      </a>\\n     </li>\\n     <li>\\n      <a href=\"/free-data-science-books\">\\n       Free Data Science Books\\n      </a>\\n     </li>\\n    </ul>\\n    <ul class=\"footer-links\">\\n     <li>\\n      <a href=\"/privacy-policy\">\\n       Privacy Policy\\n      </a>\\n     </li>\\n    </ul>\\n   </div>\\n   <div id=\"FooterFoot\">\\n    Â© 2022 LearnDataSci. All rights reserved.\\n    <br/>\\n    <br/>\\n    Use of and/or registration on any portion of this site constitutes acceptance of our\\n    <a href=\"/privacy-policy/\">\\n     Privacy Policy\\n    </a>\\n    . The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of LearnDataSci.com.\\n   </div>\\n  </footer>\\n  <div class=\"newsletter-signup-wrapper\">\\n   <div id=\"mc_embed_signup\">\\n    <h3>\\n     Get updates in your inbox\\n    </h3>\\n    <p>\\n     Join over 7,500 data science learners.\\n    </p>\\n    <form action=\"https://learndatasci.us11.list-manage.com/subscribe/post?u=789c60e0c020546463993f85b&amp;id=f53d7286eb\" class=\"validate\" id=\"mc-embedded-subscribe-form\" method=\"post\" name=\"mc-embedded-subscribe-form\" novalidate=\"\" target=\"_blank\">\\n     <div id=\"mc_embed_signup_scroll\">\\n      <input class=\"required email\" id=\"mce-EMAIL\" name=\"EMAIL\" placeholder=\"Enter your email\" type=\"email\" value=\"\"/>\\n      <div class=\"clear\" id=\"mce-responses\">\\n       <div class=\"response\" id=\"mce-error-response\" style=\"display:none\">\\n       </div>\\n       <div class=\"response\" id=\"mce-success-response\" style=\"display:none\">\\n       </div>\\n      </div>\\n      <div aria-hidden=\"true\" style=\"position: absolute; left: -5000px;\">\\n       <input name=\"b_789c60e0c020546463993f85b_f53d7286eb\" tabindex=\"-1\" type=\"text\" value=\"\"/>\\n      </div>\\n      <input class=\"button\" id=\"mc-embedded-subscribe\" name=\"subscribe\" type=\"submit\" value=\"Subscribe\"/>\\n     </div>\\n    </form>\\n   </div>\\n  </div>\\n  <script crossorigin=\"anonymous\" integrity=\"sha512-GoORoNnxst42zE3rYPj4bNBm0Q6ZRXKNH2D9nEmNvVF/z24ywVnijAWVi/09iBiVDQVf3UlZHpzhAJIdd9BXqw==\" referrerpolicy=\"no-referrer\" src=\"https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.12/ace.min.js\">\\n  </script>\\n  <script crossorigin=\"anonymous\" integrity=\"sha512-th7FxBeMVpJzGyoaIBkl+SAO+lDbe/pJUbeWJkpZ5YpckO3vzKbWURjApAKfPCxn5LG1wZDpPJ2iTdrPIJQCkg==\" src=\"https://cdnjs.cloudflare.com/ajax/libs/ace/1.4.12/ext-static_highlight.min.js\">\\n  </script>\\n  <script>\\n   window.MathJax = {\\n            tex: {\\n                inlineMath: [[\\'$\\', \\'$\\'], [\"\\\\\\\\(\", \"\\\\\\\\)\"]],\\n                displayMath: [[\\'$$\\', \\'$$\\'], [\"\\\\\\\\[\", \"\\\\\\\\]\"]],\\n                processEscapes: true\\n            },\\n            displayAlign: \"center\",\\n            svg: {\\n                fontCache: \\'global\\'\\n            }\\n        };\\n  </script>\\n  <script crossorigin=\"anonymous\" integrity=\"sha512-K90Mc/rYzO+mxOtUsnp8quUB+3T9o5L0QIk6C9O5eJ3juahzkWz751FnYs7BHtHkkNV4YLe8kvYGgK/oSHln1g==\" referrerpolicy=\"no-referrer\" src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-svg.min.js\">\\n  </script>\\n  <script src=\"https://ajax.googleapis.com/ajax/libs/jquery/2.2.4/jquery.min.js\">\\n  </script>\\n  <script async=\"\" src=\"https://storage.googleapis.com/lds-v2-static/static/js/bootstrap.min.js\">\\n  </script>\\n  <script src=\"https://storage.googleapis.com/lds-v2-static/static/js/main.js\">\\n  </script>\\n  <script>\\n   jQuery(function ($) {\\n        $(document).learnDataSciJS();\\n    });\\n  </script>\\n  <link async=\"\" href=\"https://use.typekit.net/qab0yhk.css\" rel=\"stylesheet\"/>\\n </body>\\n</html>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.prettify()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ad3b4ca62056b0ddf6609e8c0d475b5225220fb28d68e3e23627eb1e1c7d9eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
